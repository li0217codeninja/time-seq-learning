{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP2D8YYYKuxSo7oBTkV9Has",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/li0217codeninja/time-seq-learning/blob/main/timeseriesTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEQUISXvHJFt",
        "outputId": "07091a7a-ed5c-4286-cd17-8f968041ff94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fIz62e3DHc3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timeseries PyTorch Transformer"
      ],
      "metadata": {
        "id": "ES45mtocEzTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, seq_length):\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return 10000  # Replace with actual dataset size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Generate a sequence number\n",
        "        seq_num = torch.tensor(idx)\n",
        "\n",
        "        # Generate a sequence of numbers based on seq_num\n",
        "        seq_data = torch.randn(self.seq_length) * seq_num\n",
        "\n",
        "        return seq_num, seq_data\n",
        "\n",
        "def collate_fn(samples):\n",
        "    seq_nums, seq_data = zip(*samples)\n",
        "    # Pad or truncate sequences to a fixed length (optional)\n",
        "    # ...\n",
        "    return torch.stack(seq_nums), torch.stack(seq_data)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    SequenceDataset(seq_length=32),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        ")\n"
      ],
      "metadata": {
        "id": "nqSG2spHLgVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = nn.Transformer(nhead=16)\n",
        "src = torch.rand(10, 32, 512)\n",
        "tgt = torch.rand(20, 32, 512)\n",
        "out = transformer_model(src, tgt)"
      ],
      "metadata": {
        "id": "RQ7q2JjaHkWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(transformer_model.parameters())\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    # Forward pass\n",
        "    output = transformer_model(data,target)\n",
        "    # Loss calculation\n",
        "    loss = loss_fn(output, target)\n",
        "    # Backward pass and parameter update\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "3XUyed8OKcDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szgxXweSKx_K",
        "outputId": "2d916fb4-6b9b-43a0-a417-84158c233f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7a4ca5ac67a0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom train loop with LSTM\n",
        "\n",
        "1.   understand the bi-direction argument in lstm\n",
        "2.   how to dignose if any issue with model trainining\n",
        "3.   one step prediction, can we do multi-step forcast? is it just a for loop.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9C7wpfIB839I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNmodel(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size,  num_features):\n",
        "    super(RNNmodel,self).__init__() #todo check super()\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size,  batch_first=True)\n",
        "    self.dense = nn.Linear(hidden_size, num_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h, _ = self.lstm(x) # output, (h_n, c_n)\n",
        "    output = self.dense(h[:,-1,:])\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "X6wIQKdU895Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8UmRdfKOqa5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyDataset(Dataset):\n",
        "  def __init__(self,  data, sequence_len):\n",
        "    # 100 sequences, 10 time steps, 2 features per variable, 3 variables\n",
        "    self.data = data\n",
        "    self.sequence_length = sequence_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data) - self.sequence_length\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.data[idx:idx + self.sequence_length, :], dtype=torch.float32)\n",
        "        y = torch.tensor(self.data[idx + self.sequence_length, :], dtype=torch.float32)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "r3ijYD2b-3pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pM2Vf3Gk_MMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dummy data\n",
        "np.random.seed(42)\n",
        "num_samples = 1000\n",
        "sequence_length = 10\n",
        "num_features = 3\n",
        "\n",
        "data = np.random.randn(num_samples, num_features)\n",
        "\n",
        "# Create the model, dataset and data loader\n",
        "input_size = num_features\n",
        "hidden_size = 50\n",
        "output_size = num_features\n",
        "\n",
        "model = RNNmodel(input_size, hidden_size, output_size)\n",
        "dataset = DummyDataset(data, sequence_length)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(100):\n",
        "  for batch_x, batch_y in dataloader:\n",
        "        # Training logic goes here\n",
        "        # e.g., forward pass, loss computation, backward pass, and optimization\n",
        "        outputs = model(batch_x)\n",
        "        loss = nn.MSELoss()(outputs, batch_y)\n",
        "\n",
        "        # Your training steps here\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "  print(f'Epoch {epoch + 1}, Batch Loss: {loss.item()}')\n",
        "\n"
      ],
      "metadata": {
        "id": "9zsne0uN_M7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming model is your PyTorch model\n",
        "initial_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Initial number of parameters:\", initial_params)\n",
        "\n",
        "# Check if any parameters have been updated\n",
        "updated_params = sum(p.numel() for p in model.parameters())\n",
        "if updated_params > initial_params:\n",
        "    print(\"The model has been trained.\")\n",
        "else:\n",
        "    print(\"The model has not been trained.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHZ6YUx8myPn",
        "outputId": "cf092e9c-9f2e-4203-b3f0-fb98c3a95f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of parameters: 11153\n",
            "The model has not been trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "# After training, you can use the trained model for predictions\n",
        "test_sequence = torch.tensor(np.random.randn(11, num_features), dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "test_sequence\n",
        "prediction = model(test_sequence)\n",
        "\n",
        "mse = nn.MSELoss()(prediction, test_sequence[:,-1,:])\n",
        "mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cra6nA0LkDWn",
        "outputId": "6fa86cf4-57e9-4477-cdd7-d693cd63949d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9112, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "print()\n",
        "\n",
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "metadata": {
        "id": "OQw8ot8Nqcd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Custom Dataloader\n",
        "\n",
        "ref: [Biswajit -  data loader](https://biswajitsahoo1111.github.io/post/reading-multiple-csv-files-in-pytorch/)"
      ],
      "metadata": {
        "id": "yooQwgGzcvvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate random files"
      ],
      "metadata": {
        "id": "g-_FH685dBS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "IOA_IaJidFje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.rand(1024, ).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxvVYHzAeEKL",
        "outputId": "3788644e-b913-4167-ec2b-e3173c9f5099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rand_csv_files(classes, num_files):\n",
        "  try:\n",
        "    os.mkdir('./random_data')\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  for c in classes:\n",
        "    for i in range(num_files):\n",
        "      data = np.random.rand(1024, )\n",
        "      file_name = './random_data/' + eval('c') + '_' + '{0:03}'.format(i+1) + '.csv'\n",
        "      np.savetxt(file_name, data, delimiter=',', header='data', comments='')\n",
        "\n",
        "create_rand_csv_files(['type_a', 'type_b', 'type_c'], 10)"
      ],
      "metadata": {
        "id": "EacbC-nwdRen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write custom dataloader"
      ],
      "metadata": {
        "id": "1i-zCJrik7tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "print('PyTorch Version: ', torch.__version__)\n",
        "import glob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP0Uj9_YpjiG",
        "outputId": "9077a881-6e1d-4691-fcf0-d15e4145e407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, filenames, batch_size):\n",
        "    # filenames: a list of strings that contain all file names\n",
        "    # batch_size: determins the number of files that we read in chunk\n",
        "    self.filenames = filenames\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.ceil(len(self.filenames)/float(self.batch_size))) #number batch/chunk of files\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    #idx: index of the chunk\n",
        "    # in this method, we do all preprocessing of the data\n",
        "\n",
        "    # first read data in a chunk and preprocess -> extract data and labels\n",
        "    batch_x = self.filenames[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "\n",
        "    data = []\n",
        "    labels = []\n",
        "    label_classes = ['type_a','type_b','type_c']\n",
        "\n",
        "    for file in batch_x:\n",
        "      temp = pd.read_csv(file)\n",
        "\n",
        "      # preprocess step - customize this to extract and reshape feautres\n",
        "      data.append(temp.values.reshape(32,32,1))\n",
        "\n",
        "\n",
        "      # customize this to extract labels\n",
        "      #breakpoint()\n",
        "      pattern = eval(\"file[14:20]\")\n",
        "      for j in range(len(label_classes)):\n",
        "        #breakpoint()\n",
        "        if re.match(pattern, label_classes[j]):\n",
        "          labels.append(j)\n",
        "\n",
        "    # pytoch channel fisrt conventions. check conventions\n",
        "    data = np.asarray(data).reshape(-1, 1, 32, 32)\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    # the following condition is actually needed in pytorch to prevent infinite loop\n",
        "    # verify if this is true by removing the cond\n",
        "    if idx == self.__len__():\n",
        "      raise IndexError\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "files = glob.glob(\"./random_data/*\")\n",
        "print(files[:5])\n",
        "\n",
        "check_dataset = CustomDataset(filenames= files, batch_size=10)\n",
        "check_dataset.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTwqsq30k5Ly",
        "outputId": "d5c1652f-04d2-4f57-c1c4-4fc5dcf7de32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./random_data/type_a_001.csv', './random_data/type_c_003.csv', './random_data/type_b_010.csv', './random_data/type_b_003.csv', './random_data/type_c_009.csv']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (data, labels) in enumerate(check_dataset):\n",
        "  print(data.shape, labels.shape)\n",
        "  print(labels)\n",
        "  if i==3: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zvy8R7xuAzr",
        "outputId": "e444a301-487a-449a-f357-0e331f649bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 1, 32, 32) (10,)\n",
            "[0 2 1 1 2 0 0 0 0 1]\n",
            "(10, 1, 32, 32) (10,)\n",
            "[1 0 2 0 2 1 1 2 1 1]\n",
            "(10, 1, 32, 32) (10,)\n",
            "[2 0 1 1 0 0 2 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P5Z8DXbA1Ag7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time series Transformer Implementation\n",
        "reference:\n",
        "https://towardsdatascience.com/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e\n",
        "\n",
        "shell-gpt notes\n",
        "https://github.com/TheR1D/shell_gpt\n",
        "\n",
        "\n",
        "notes:\n",
        "1. position encoder: supports multi-variates\n",
        "2. checkout implementation of nn.TransformerEncoderLayer, nn.TransformerDecoderLayer\n",
        "3. what is src_mask and tgt_mask\n",
        "\n"
      ],
      "metadata": {
        "id": "y05DjKCi1Bd8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lZWcradi1REq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}